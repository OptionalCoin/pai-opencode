# Local Ollama - Fully offline, private deployment
# All data stays on your machine. No API key required.
#
# IMPORTANT: You must have Ollama installed and models pulled locally.
# The models below are SUGGESTIONS - replace with what you have installed.
#
# To check available models: ollama list
# To pull a model: ollama pull <model>
#
# Recommended models to pull:
#   ollama pull qwen2.5-coder:32b    # Most capable coding model
#   ollama pull qwen2.5-coder:7b     # Standard coding model
#   ollama pull qwen2.5-coder:1.5b   # Fast budget model
#
# Alternative suggestions:
#   ollama pull deepseek-coder-v2:latest  # Great for code
#   ollama pull llama3.2:latest           # General purpose
#   ollama pull codellama:latest          # Code-focused
#
name: local
description: Local Ollama models - offline/private, customize to your installed models
models:
  default: ollama/qwen2.5-coder:7b

  # 3-Tier: Most Capable → Standard → Budget
  # CUSTOMIZE THESE to match your locally installed models!
  Algorithm: ollama/qwen2.5-coder:32b
  Architect: ollama/qwen2.5-coder:7b
  Engineer: ollama/qwen2.5-coder:7b
  general: ollama/qwen2.5-coder:7b
  explore: ollama/qwen2.5-coder:1.5b
  Intern: ollama/qwen2.5-coder:1.5b
  writer: ollama/qwen2.5-coder:7b
  ClaudeResearcher: ollama/qwen2.5-coder:7b
  GeminiResearcher: ollama/qwen2.5-coder:7b
  GrokResearcher: ollama/qwen2.5-coder:7b
  PerplexityResearcher: ollama/qwen2.5-coder:7b
  PerplexityProResearcher: ollama/qwen2.5-coder:7b
  QATester: ollama/qwen2.5-coder:7b
  Pentester: ollama/qwen2.5-coder:7b
  Designer: ollama/qwen2.5-coder:7b
  Artist: ollama/qwen2.5-coder:7b
  CodexResearcher: ollama/qwen2.5-coder:7b
  researcher: ollama/qwen2.5-coder:7b
